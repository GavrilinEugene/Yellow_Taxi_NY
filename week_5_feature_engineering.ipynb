{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import scipy as sc\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С прошлой недели я ушёл с результатом 19.5: xgboost без тюнинга, где использовались:\n",
    "        - дневные и часовые лаги\n",
    "        - скользящее среднее на 6 часов,\n",
    "        - гармонические фичи для сезонностей\n",
    "        - дни недели\n",
    "На этой неделе попробовал пообучаться на чём-то более быстром, чем xgboost (подбор признаков), затем взял параметры для xgboost и посчитал две версии. Здесь показана версия на ошибку 16.7, потом я добавил ещё скользящих сумм, это считалось 12 часов на достаточно мощном компьютере, и это дало результат 16.19. Но такое время не приемлимо.\n",
    "Что было добавлено:\n",
    "        - знаменательные даты (не все давали прирост)\n",
    "        - ещё скользящих средник\n",
    "        - погода (парсинг погоды в соседнем ноутбуке)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# все данные\n",
    "df = pd.read_csv('processed_data/all_trip_data.csv', index_col='time')\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sin-cos\n",
    "def make_fourier_features(data, num_end, f_ind='week_'):\n",
    "    length = data.shape[0]   \n",
    "    for i in range(1, num_end + 1):\n",
    "        sin = \"s_\" + f_ind + str(i)\n",
    "        cos = \"c_\" + f_ind + str(i)\n",
    "        data[sin] = np.sin(2*np.pi*i*np.arange(1, length+1)/168.0)\n",
    "        data[cos] = np.cos(2*np.pi*i*np.arange(1, length+1)/168.0)\n",
    "\n",
    "# day_of_week\n",
    "def make_week_day_features(data):\n",
    "    data['week']= pd.DatetimeIndex(data.index).dayofweek\n",
    "    data['day']= pd.DatetimeIndex(data.index).day\n",
    "    data['hour']= pd.DatetimeIndex(data.index).hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данные для мая\n",
    "R = 102\n",
    "H = 739\n",
    "Q_may = 0\n",
    "error_for_month = 1.0/(R*H*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base features\n",
    "def make_features(region_df, offset, degree, K_d, K_h):\n",
    "     \n",
    "    # 6-hours-window\n",
    "    region_df['last_6_hours_sum'] = region_df['val'].rolling(6).sum().fillna(0)\n",
    "    region_df['last_6_hours_mean'] = region_df['last_6_hours_sum']/6\n",
    "    \n",
    "    # fourier components\n",
    "    make_fourier_features(region_df, degree)\n",
    "    \n",
    "    # weekday dummy components\n",
    "    make_week_day_features(region_df)\n",
    "    \n",
    "    # day lags\n",
    "    for day_lag in range(1, K_d):\n",
    "        region_df['day_lag_'+str(day_lag)] = [0]*offset + region_df[offset-24*day_lag:-24*day_lag]['val'].values.tolist()\n",
    "        \n",
    "    # hour lags\n",
    "    for hour_lag in range(1, K_h):\n",
    "        region_df['hour_lag_'+str(hour_lag)] = [0]*offset + region_df[offset-hour_lag:-hour_lag]['val'].values.tolist()\n",
    "        \n",
    "    return region_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция подсчёта ошибки на конкретном регионе (так лучше, чем считать все, как было сделано на 5ой неделе)\n",
    "# с базовыми признаками\n",
    "def train_predict(data, train_time_end, test_time_end, region, denom, f_make_features,\n",
    "                       pred_start='2016-05-01', pred_end='2016-05-31', degree=49,\n",
    "                       K_d=2, K_h=8):\n",
    "    \n",
    "    region_df = pd.DataFrame(data.loc[:test_time_end][str(region)].values, columns=['val'],\n",
    "                            index = data.loc[:test_time_end].index)\n",
    "       \n",
    "    abs_err_sum = 0\n",
    "    offset = max(24*K_d, K_h, 12)\n",
    "    \n",
    "    # базовые признаки\n",
    "    region_df = f_make_features(region_df, offset, degree, K_d, K_h)\n",
    "             \n",
    "    for i in range(6):\n",
    "        # Training \n",
    "        train_length = data.loc[:train_time_end].shape[0] - i\n",
    "        regressor = ElasticNet(alpha=0.01, l1_ratio=0.4)\n",
    "        \n",
    "        X_train = region_df.iloc[offset:train_length].drop(['val'], axis = 1)\n",
    "        y_train = region_df.iloc[offset + i + 1:train_length + i + 1].val\n",
    "        regressor.fit(X_train,y_train)\n",
    "\n",
    "        # predictions\n",
    "        X_test = region_df[train_time_end:test_time_end].drop(['val'], axis=1)\n",
    "        prediction = regressor.predict(X_test)\n",
    "        prediction[prediction < 0] = 0.0\n",
    "        \n",
    "        # 6 hours combinations\n",
    "        begin_hour = pred_start +' 0' + str(0 + i)+':00:00'\n",
    "        end_hour = pred_end + ' ' + str(18 + i) + ':00:00'\n",
    "        \n",
    "        error = denom * np.abs(prediction - data.loc[begin_hour:end_hour][str(region)].values)\n",
    "        abs_err_sum += error.sum()\n",
    "        \n",
    "#     print(region, abs_err_sum)    \n",
    "    del region_df\n",
    "    return abs_err_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка для всех регионов\n",
    "def calculate_error(data_time_end, train_time_end, test_time_end, feature_generation_function):\n",
    "    Q_error = 0\n",
    "    for region in df.columns:\n",
    "        res = train_predict(df.loc[:data_time_end], \n",
    "                            train_time_end,  test_time_end, region, \n",
    "                            error_for_month, feature_generation_function)\n",
    "        Q_error += res\n",
    "    print (\"\\n\", Q_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18.550081918729685\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# для мая\n",
    "train_time_end = '2016-04-30 23:00:00'\n",
    "test_time_end = '2016-05-31 17:00:00'\n",
    "calculate_error('2016-05-31 23:00:00',train_time_end, test_time_end, make_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10689187046443284\n",
      "0.6501056918196817\n",
      "Wall time: 5.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# проверка на базовых фичах \n",
    "err = train_predict(df.loc[:'2016-05-31 23:00:00'], \n",
    "                    train_time_end, test_time_end, 1075, error_for_month, make_features)\n",
    "\n",
    "print (err)\n",
    "err = train_predict(df.loc[:'2016-05-31 23:00:00'], \n",
    "                    train_time_end, test_time_end, 1232, error_for_month, make_features)\n",
    "print (err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, попробуем добавить праздники"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# праздники учитывал только для своего промежутка полученных данных: 08-15 : 06-16,\n",
    "def make_features_with_holidays(region_df, offset, degree, K_d, K_h):\n",
    "     \n",
    "    region_df = make_features(region_df, offset, degree, K_d, K_h)\n",
    "    \n",
    "    region_df['pre_new_year'] = [1 if date.month == 12 and date.day == 31 else 0 for date in region_df.index]\n",
    "    region_df['chistmas'] = [1 if date.month == 12 and date.day == 25 else 0 for date in region_df.index] \n",
    "    region_df['new_year'] = [1 if date.month == 1 and date.day == 1 else 0 for date in region_df.index]\n",
    "    region_df['valentine_day'] = [1 if date.month == 2 and date.day == 14 else 0 for date in region_df.index]\n",
    "    region_df['9/11'] = [1 if date.month == 9 and date.day == 11 else 0 for date in region_df.index]\n",
    "\n",
    "    # not common holiday date\n",
    "    # thanks_giving_day : last thursday(November)\n",
    "    region_df['thanks_giving_day'] = [1 if date.month == 11 and date.day == 26 \n",
    "                                      else 0 for date in region_df.index]\n",
    "    # president's day: third fmonday(February)\n",
    "    region_df['president_day'] = [1 if date.month == 2 and ((date.year == 2015 and date.day == 16) or\n",
    "                                       (date.year == 2016 and date.day == 15))\n",
    "                                  else 0 for date in region_df.index]\n",
    "    \n",
    "    return region_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10673692336065305\n",
      "0.6494270304927184\n",
      "Wall time: 5.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# base features + holidays \n",
    "err = train_predict(df.loc[:'2016-05-31 23:00:00'],\n",
    "                    train_time_end, test_time_end, 1075, error_for_month, make_features_with_holidays)\n",
    "\n",
    "print (err)\n",
    "err = train_predict(df.loc[:'2016-05-31 23:00:00'],\n",
    "                    train_time_end, test_time_end, 1232, error_for_month, make_features_with_holidays)\n",
    "print (err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Праздники помогли слегка снизить ошибку, но незначительно. Думаю проблема в небольшом датасете и числе праздников, многие значительные праздники не обозначены, т.к вообще не встречаются в рассмотренных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather history\n",
    "Добавим признаки, которые относятся к погоде. Погода была получена парсингом сайта https://www.wunderground.com\n",
    "Код, получающий данные приведён в соседнем ноутбуке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv('weather.csv',names = ['time','temperature','wind', 'old_time'],\n",
    "                           index_col = 'time')\n",
    "\n",
    "# приводим в порядок типы данных\n",
    "weather_data.index = pd.to_datetime(weather_data.index)\n",
    "weather_data = weather_data[['temperature','wind']]['2015-08-01 00:00:00':'2016-06-30 17:00:00']\n",
    "weather_data['temperature'] = (weather_data['temperature']).astype(float)\n",
    "weather_data['wind'] = (weather_data['wind']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# праздники учитывал только для своего промежутка полученных данных: 08-15 : 06-16,\n",
    "def make_features_with_holidays_and_weather(region_df, offset, degree, K_d, K_h):\n",
    "     \n",
    "    region_df = make_features_with_holidays(region_df, offset, degree, K_d, K_h)\n",
    "    \n",
    "    region_df['temperature'] = weather_data['temperature'][region_df.index]\n",
    "    region_df['wind'] = weather_data['wind'][region_df.index]\n",
    "   \n",
    "    return region_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10742282511658169\n",
      "0.6459172468770675\n",
      "Wall time: 6.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# base features + holidays + weather\n",
    "err = train_predict(df.loc[:'2016-05-31 23:00:00'],\n",
    "                    train_time_end, test_time_end, 1075, \n",
    "                    error_for_month, make_features_with_holidays_and_weather)\n",
    "print (err)\n",
    "\n",
    "err = train_predict(df.loc[:'2016-05-31 23:00:00'],\n",
    "                    train_time_end, test_time_end, 1232, \n",
    "                    error_for_month, make_features_with_holidays_and_weather)\n",
    "print (err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 18.509385182486668\n",
      "Wall time: 4min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# для мая\n",
    "train_time_end = '2016-04-30 23:00:00'\n",
    "test_time_end = '2016-05-31 17:00:00'\n",
    "calculate_error('2016-05-31 23:00:00',train_time_end, test_time_end, make_features_with_holidays_and_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка снизилась ещё чуть-чуть, но я ожидал больше.\n",
    "Попробуем вернуться к xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_xgboost(data, train_time_end, test_time_end, region, denom, f_make_features,\n",
    "                          pred_start='2016-05-01', pred_end='2016-05-31', degree=49,\n",
    "                          K_d=2, K_h=8):\n",
    "    \n",
    "    region_df = pd.DataFrame(data.loc[:test_time_end][str(region)].values, columns=['val'],\n",
    "                            index = data.loc[:test_time_end].index)\n",
    "       \n",
    "    abs_err_sum = 0\n",
    "    offset = max(24*K_d, K_h, 12)\n",
    "    \n",
    "    # create features\n",
    "    region_df = f_make_features(region_df, offset, degree, K_d, K_h)\n",
    "    \n",
    "    for i in range(6):\n",
    "        # Training \n",
    "        train_length = data.loc[:train_time_end].shape[0] - i\n",
    "        X_train = region_df.iloc[offset:train_length].drop(['val'], axis=1)\n",
    "        y_train = region_df.iloc[offset + i + 1:train_length + i + 1].val\n",
    "        xgb_train = xgb.DMatrix(X_train, y_train)\n",
    " \n",
    "        params={\n",
    "            'max_depth': 6, \n",
    "            'eta': 0.05, \n",
    "            'colsample_bytree': 1,\n",
    "            \"min_child_weight\": 6, \n",
    "            'subsample': 0.8,\n",
    "            'gamma': 1, # L2\n",
    "            'alpha': 0.01, # L1\n",
    "            'objective': \"reg:linear\",\n",
    "            'eval_metric': 'mae',\n",
    "            'nthread': -1\n",
    "        }\n",
    "        evals = [(xgb_train, 'train')]\n",
    "        bst = xgb.train(params, xgb_train, num_boost_round=200, early_stopping_rounds=6, \n",
    "                        evals=evals, verbose_eval=False)\n",
    "       \n",
    "        # predictions\n",
    "        X_test= xgb.DMatrix(region_df[train_time_end:].drop(['val'], axis=1))\n",
    "        prediction = bst.predict(X_test)\n",
    "        \n",
    "        prediction[prediction < 0] = 0.0\n",
    "        \n",
    "        # 6 hours combinations\n",
    "        begin_hour = pred_start +' 0' + str(0 + i)+':00:00'\n",
    "        end_hour = pred_end + ' ' + str(18 + i) + ':00:00'\n",
    "        \n",
    "        error = denom * np.abs(prediction - data.loc[begin_hour:end_hour][str(region)].values)\n",
    "        abs_err_sum += error.sum()\n",
    " \n",
    "    del region_df\n",
    "    return abs_err_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09988459564931054\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_time_end = '2016-04-30 23:00:00'\n",
    "test_time_end = '2016-05-31 17:00:00'\n",
    "# base features + holidays + weather + xgboost\n",
    "err = train_predict_xgboost(df.loc[:'2016-05-31 23:00:00'],\n",
    "                    train_time_end, test_time_end, 1075, \n",
    "                    error_for_month, make_features_with_holidays_and_weather)\n",
    "print (err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже есть смысл обучать xgboost. Посчитаем весь май"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 102\n",
    "H = 739\n",
    "error_for_month = 1.0/(R*H*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075 0.09988459564931054\n",
      "1076 0.16034718611060164\n",
      "1077 0.11318358798603523\n",
      "1125 0.0973023118010349\n",
      "1126 0.19056344492816468\n",
      "1127 0.249272259295525\n",
      "1128 0.2929400712394261\n",
      "1129 0.31781208888503487\n",
      "1130 0.4102682671191039\n",
      "1131 0.19756077946007847\n",
      "1132 0.12787972757787208\n",
      "1172 0.029028751553860407\n",
      "1173 0.06649647945506551\n",
      "1174 0.06057241108357689\n",
      "1175 0.03963101294850412\n",
      "1176 0.0441782512241547\n",
      "1177 0.3096335975675111\n",
      "1178 0.3871139470631386\n",
      "1179 0.3827862146737501\n",
      "1180 0.44412091307052315\n",
      "1181 0.7471842666069024\n",
      "1182 0.4184093852368179\n",
      "1183 0.19433798221865906\n",
      "1184 0.04277547777513005\n",
      "1221 0.023610894557268218\n",
      "1222 0.033146593675142694\n",
      "1223 0.052645007407106356\n",
      "1224 0.05679678895422936\n",
      "1225 0.022892368493349354\n",
      "1227 0.2031780333617119\n",
      "1228 0.34224925117573984\n",
      "1229 0.40391123142269597\n",
      "1230 0.531288316845393\n",
      "1231 0.6046729144383548\n",
      "1232 0.6200928468454645\n",
      "1233 0.49330857833169584\n",
      "1234 0.3242990193996268\n",
      "1235 0.15949765900208343\n",
      "1272 0.02715373263928711\n",
      "1273 0.05128736975035571\n",
      "1274 0.02512038431455634\n",
      "1278 0.0356977141665644\n",
      "1279 0.05676143924122701\n",
      "1280 0.1948683856215052\n",
      "1281 0.5736463312895358\n",
      "1282 0.7210052763253771\n",
      "1283 0.27163420314607145\n",
      "1284 0.11985491111712347\n",
      "1285 0.25337182880328296\n",
      "1286 0.19959906117805004\n",
      "1287 0.09414256258496781\n",
      "1326 0.05394443946530078\n",
      "1327 0.06599822999699792\n",
      "1331 0.06906153265048547\n",
      "1332 0.28426953921701453\n",
      "1333 0.4211539293034106\n",
      "1334 0.4269494769747534\n",
      "1335 0.14374419233948632\n",
      "1336 0.08459578877054491\n",
      "1337 0.10588000441010408\n",
      "1338 0.10501130557990579\n",
      "1339 0.028006762487435378\n",
      "1376 0.03719102788823602\n",
      "1377 0.028254796302829815\n",
      "1378 0.026017912580796113\n",
      "1380 0.026663483924859906\n",
      "1382 0.048209771638744556\n",
      "1383 0.24429962286944565\n",
      "1384 0.38278009580547595\n",
      "1385 0.2308894223140464\n",
      "1386 0.06911094027462908\n",
      "1387 0.06101127464511675\n",
      "1388 0.050839560136395505\n",
      "1389 0.0371822438103453\n",
      "1390 0.04179726859118801\n",
      "1426 0.020773593694451614\n",
      "1431 0.04696501374557824\n",
      "1434 0.02951550797661632\n",
      "1435 0.024744566586494435\n",
      "1436 0.056210813064593426\n",
      "1437 0.06761201378777633\n",
      "1438 0.029425934672063607\n",
      "1439 0.02577903361931034\n",
      "1441 0.020692729312981127\n",
      "1442 0.027333104727710344\n",
      "1480 0.030751275777114596\n",
      "1482 0.029868388210071747\n",
      "1483 0.0272171641697787\n",
      "1530 0.03281704808326962\n",
      "1532 0.022946834868908722\n",
      "1533 0.029392106452795372\n",
      "1580 0.020230785605302618\n",
      "1630 0.019498642738523538\n",
      "1684 0.048872194487058845\n",
      "1733 0.021258774525564638\n",
      "1734 0.3009814963118207\n",
      "1783 0.31248674085011463\n",
      "2068 0.18111078749724002\n",
      "2069 0.045036266642671276\n",
      "2118 0.22729285194902762\n",
      "2119 0.1288321968884137\n",
      "2168 0.17257737081661298\n",
      "Wall time: 22min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# для мая\n",
    "Q_error = 0\n",
    "train_time_end = '2016-04-30 23:00:00'\n",
    "test_time_end = '2016-05-31 17:00:00'\n",
    "for region in df.columns:   \n",
    "    \n",
    "    res = train_predict_xgboost(df.loc[:'2016-05-31 23:00:00'], \n",
    "                            train_time_end,  test_time_end, region, \n",
    "                            error_for_month, make_features_with_holidays_and_weather)\n",
    "    print(region,res)\n",
    "    Q_error += res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неплохой результат (съехал, увы, было 16.99) за страшное время. Сделаем то же самое для июня с сабмитом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_xgboost2(data, train_time_end, test_time_end, region, denom, f_make_features,\n",
    "                          pred_start='2016-05-01', pred_end='2016-05-31', degree=49,\n",
    "                          K_d=2, K_h=8):\n",
    "    \n",
    "    region_df = pd.DataFrame(data.loc[:test_time_end][str(region)].values, columns=['val'],\n",
    "                            index = data.loc[:test_time_end].index)\n",
    "       \n",
    "    abs_err_sum = 0\n",
    "    offset = max(24*K_d, K_h, 12)\n",
    "    \n",
    "    # create features\n",
    "    region_df = f_make_features(region_df, offset, degree, K_d, K_h)\n",
    "    \n",
    "    # submit\n",
    "    submit_ids = []\n",
    "    submit_preds = []\n",
    "    \n",
    "    for i in range(6):\n",
    "        # Training \n",
    "        train_length = data.loc[:train_time_end].shape[0] - i\n",
    "        X_train = region_df.iloc[offset:train_length].drop(['val'], axis=1)\n",
    "        y_train = region_df.iloc[offset + i + 1:train_length + i + 1].val\n",
    "        xgb_train = xgb.DMatrix(X_train, y_train)\n",
    " \n",
    "        params={\n",
    "            'max_depth': 6, \n",
    "            'eta': 0.05, \n",
    "            'colsample_bytree': 1,\n",
    "            \"min_child_weight\": 6, \n",
    "            'subsample': 0.8,\n",
    "            'gamma': 1, # L2\n",
    "            'alpha': 0.01, # L1\n",
    "            'objective': \"reg:linear\",\n",
    "            'eval_metric': 'mae',\n",
    "            'nthread': -1\n",
    "        }\n",
    "        evals = [(xgb_train, 'train')]\n",
    "        bst = xgb.train(params, xgb_train, num_boost_round=200, early_stopping_rounds=6, \n",
    "                        evals=evals, verbose_eval=False)\n",
    "       \n",
    "        # predictions\n",
    "        X_test= xgb.DMatrix(region_df[train_time_end:].drop(['val'], axis=1))\n",
    "        prediction = bst.predict(X_test)\n",
    "        \n",
    "        prediction[prediction < 0] = 0.0\n",
    "        \n",
    "        # 6 hours combinations\n",
    "        begin_hour = pred_start +' 0' + str(0 + i)+':00:00'\n",
    "        end_hour = pred_end + ' ' + str(18 + i) + ':00:00'\n",
    "        \n",
    "        error = denom * np.abs(prediction - data.loc[begin_hour:end_hour][str(region)].values)\n",
    "        abs_err_sum += error.sum()\n",
    "        \n",
    "        \n",
    "        indexes = region_df[train_time_end:].index \n",
    "        submit_ids.append((pd.Series([str(region)] * indexes.size) + '_' \n",
    "                           + list(map(lambda x: x.strftime('%Y-%m-%d'), indexes)) + '_' \\\n",
    "                            + list(map(lambda x: str(x.hour) + '_' + str(i+1), indexes))).values)\n",
    "        submit_preds.append(prediction)\n",
    " \n",
    "    del region_df\n",
    "    return abs_err_sum,submit_ids,submit_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1032373652934832\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# проверка\n",
    "train_time_end = '2016-04-30 23:00:00'\n",
    "test_time_end = '2016-05-31 17:00:00'\n",
    "# base features + holidays + weather + xgboost\n",
    "err, submit_ids,submit_preds = train_predict_xgboost2(df.loc[:'2016-05-31 23:00:00'],\n",
    "                                    train_time_end, test_time_end, 1075, \n",
    "                                    error_for_month, make_features_with_holidays_and_weather)\n",
    "print (err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры для июня\n",
    "R = 102\n",
    "H = 715\n",
    "error_for_month = 1.0/(R*H*6)\n",
    "Q_error = 0\n",
    "submit_ids = []\n",
    "submit_preds = []\n",
    "\n",
    "train_time_end = '2016-05-31 23:00:00'\n",
    "test_time_end = '2016-06-30 17:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region: 1075, error: 0.108112, current_error: 0.108112\n",
      "region: 1076, error: 0.147991, current_error: 0.256103\n",
      "region: 1077, error: 0.121522, current_error: 0.377625\n",
      "region: 1125, error: 0.086530, current_error: 0.464155\n",
      "region: 1126, error: 0.195481, current_error: 0.659636\n",
      "region: 1127, error: 0.253577, current_error: 0.913213\n",
      "region: 1128, error: 0.280238, current_error: 1.193452\n",
      "region: 1129, error: 0.317652, current_error: 1.511103\n",
      "region: 1130, error: 0.417340, current_error: 1.928443\n",
      "region: 1131, error: 0.188212, current_error: 2.116655\n",
      "region: 1132, error: 0.123196, current_error: 2.239851\n",
      "region: 1172, error: 0.020410, current_error: 2.260261\n",
      "region: 1173, error: 0.051244, current_error: 2.311505\n",
      "region: 1174, error: 0.060935, current_error: 2.372440\n",
      "region: 1175, error: 0.036615, current_error: 2.409055\n",
      "region: 1176, error: 0.041789, current_error: 2.450843\n",
      "region: 1177, error: 0.278852, current_error: 2.729696\n",
      "region: 1178, error: 0.471939, current_error: 3.201635\n",
      "region: 1179, error: 0.406677, current_error: 3.608312\n",
      "region: 1180, error: 0.461452, current_error: 4.069764\n",
      "region: 1181, error: 0.662362, current_error: 4.732126\n",
      "region: 1182, error: 0.457161, current_error: 5.189287\n",
      "region: 1183, error: 0.170635, current_error: 5.359922\n",
      "region: 1184, error: 0.038401, current_error: 5.398322\n",
      "region: 1221, error: 0.024258, current_error: 5.422580\n",
      "region: 1222, error: 0.030717, current_error: 5.453297\n",
      "region: 1223, error: 0.041488, current_error: 5.494785\n",
      "region: 1224, error: 0.053099, current_error: 5.547884\n",
      "region: 1225, error: 0.022616, current_error: 5.570500\n",
      "region: 1227, error: 0.181658, current_error: 5.752158\n",
      "region: 1228, error: 0.303174, current_error: 6.055332\n",
      "region: 1229, error: 0.361064, current_error: 6.416396\n",
      "region: 1230, error: 0.507679, current_error: 6.924075\n",
      "region: 1231, error: 0.602755, current_error: 7.526830\n",
      "region: 1232, error: 0.603319, current_error: 8.130149\n",
      "region: 1233, error: 0.444814, current_error: 8.574962\n",
      "region: 1234, error: 0.313897, current_error: 8.888859\n",
      "region: 1235, error: 0.165373, current_error: 9.054232\n",
      "region: 1272, error: 0.026045, current_error: 9.080277\n",
      "region: 1273, error: 0.040379, current_error: 9.120656\n",
      "region: 1274, error: 0.021963, current_error: 9.142618\n",
      "region: 1278, error: 0.031230, current_error: 9.173848\n",
      "region: 1279, error: 0.053244, current_error: 9.227093\n",
      "region: 1280, error: 0.209524, current_error: 9.436617\n",
      "region: 1281, error: 0.546423, current_error: 9.983040\n",
      "region: 1282, error: 0.681513, current_error: 10.664553\n",
      "region: 1283, error: 0.261486, current_error: 10.926039\n",
      "region: 1284, error: 0.126998, current_error: 11.053038\n",
      "region: 1285, error: 0.285099, current_error: 11.338137\n",
      "region: 1286, error: 0.217309, current_error: 11.555446\n",
      "region: 1287, error: 0.090432, current_error: 11.645878\n",
      "region: 1326, error: 0.046993, current_error: 11.692871\n",
      "region: 1327, error: 0.063304, current_error: 11.756175\n",
      "region: 1331, error: 0.063999, current_error: 11.820174\n",
      "region: 1332, error: 0.258579, current_error: 12.078753\n",
      "region: 1333, error: 0.384651, current_error: 12.463404\n",
      "region: 1334, error: 0.400128, current_error: 12.863532\n",
      "region: 1335, error: 0.122444, current_error: 12.985976\n",
      "region: 1336, error: 0.087594, current_error: 13.073570\n",
      "region: 1337, error: 0.096135, current_error: 13.169706\n",
      "region: 1338, error: 0.088160, current_error: 13.257866\n",
      "region: 1339, error: 0.030835, current_error: 13.288700\n",
      "region: 1376, error: 0.032603, current_error: 13.321303\n",
      "region: 1377, error: 0.026742, current_error: 13.348045\n",
      "region: 1378, error: 0.023129, current_error: 13.371175\n",
      "region: 1380, error: 0.026793, current_error: 13.397968\n",
      "region: 1382, error: 0.040836, current_error: 13.438804\n",
      "region: 1383, error: 0.194958, current_error: 13.633762\n",
      "region: 1384, error: 0.356836, current_error: 13.990598\n",
      "region: 1385, error: 0.248663, current_error: 14.239261\n",
      "region: 1386, error: 0.077463, current_error: 14.316724\n",
      "region: 1387, error: 0.062403, current_error: 14.379127\n",
      "region: 1388, error: 0.056556, current_error: 14.435683\n",
      "region: 1389, error: 0.038440, current_error: 14.474124\n",
      "region: 1390, error: 0.038963, current_error: 14.513086\n",
      "region: 1426, error: 0.017259, current_error: 14.530345\n",
      "region: 1431, error: 0.049989, current_error: 14.580334\n",
      "region: 1434, error: 0.025177, current_error: 14.605511\n",
      "region: 1435, error: 0.029145, current_error: 14.634656\n",
      "region: 1436, error: 0.054743, current_error: 14.689399\n",
      "region: 1437, error: 0.080248, current_error: 14.769647\n",
      "region: 1438, error: 0.032713, current_error: 14.802360\n",
      "region: 1439, error: 0.025302, current_error: 14.827661\n",
      "region: 1441, error: 0.019204, current_error: 14.846865\n",
      "region: 1442, error: 0.027014, current_error: 14.873879\n",
      "region: 1480, error: 0.030157, current_error: 14.904036\n",
      "region: 1482, error: 0.028070, current_error: 14.932106\n",
      "region: 1483, error: 0.026356, current_error: 14.958461\n",
      "region: 1530, error: 0.032234, current_error: 14.990696\n",
      "region: 1532, error: 0.024289, current_error: 15.014984\n",
      "region: 1533, error: 0.030720, current_error: 15.045704\n",
      "region: 1580, error: 0.018634, current_error: 15.064338\n",
      "region: 1630, error: 0.018734, current_error: 15.083072\n",
      "region: 1684, error: 0.049111, current_error: 15.132183\n",
      "region: 1733, error: 0.020955, current_error: 15.153138\n",
      "region: 1734, error: 0.307673, current_error: 15.460812\n",
      "region: 1783, error: 0.322990, current_error: 15.783801\n",
      "region: 2068, error: 0.175674, current_error: 15.959476\n",
      "region: 2069, error: 0.052500, current_error: 16.011976\n",
      "region: 2118, error: 0.222733, current_error: 16.234708\n",
      "region: 2119, error: 0.260056, current_error: 16.494764\n",
      "region: 2168, error: 0.230652, current_error: 16.725416\n",
      "Wall time: 27min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ещё поднимем K_d до 7 (дневные лаги)\n",
    "for region in df.columns:\n",
    "    err, ids, pred = train_predict_xgboost2(df.loc[:'2016-06-30 23:00:00'], \n",
    "                                           train_time_end, test_time_end , region, error_for_month, \n",
    "                                           make_features_with_holidays_and_weather,\n",
    "                                           '2016-06-01', '2016-06-30', degree=49, K_d=7, K_h=8)\n",
    "     \n",
    "    Q_error += err\n",
    "    print ('region: %s, error: %f, current_error: %f' %(region, err, Q_error))\n",
    "    submit_ids.append(ids)\n",
    "    submit_preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.array(submit_preds).ravel(), index=np.array(submit_ids).ravel(), columns=['y'])\n",
    "pred_df.index.name = 'id'\n",
    "pred_df.to_csv(\"w6.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на лучший сабмит, считался 12 часов: https://inclass.kaggle.com/c/yellowtaxi/leaderboard?submissionId=5039542\n",
    "Улучшение составило ~3.5 относительно прошлой недели"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
